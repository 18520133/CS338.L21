{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet50.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1oHV4SiN99NqeymW9Vm6WoTadUY71NRdN","authorship_tag":"ABX9TyONI74tX1U+97ed+Bu3thyf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"A7kmbRfzTMp9"},"source":["#Import thư viện"]},{"cell_type":"code","metadata":{"id":"3qn5sO69ft9G"},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import tensorflow as tf\n","from matplotlib import pyplot as plt\n","from sklearn.metrics import cohen_kappa_score\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.densenet import DenseNet121\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","import keras\n","import cv2\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","import cv2\n","import os\n","from keras.callbacks import Callback\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils.multiclass import unique_labels\n","from sklearn.utils import class_weight\n","#print(os.listdir(\"../input\"))\n","\n","# Any results you write to the current directory are saved as output."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDF-bYNWRfbu"},"source":["class QWKCallback(Callback):\n","    def __init__(self,val_data):\n","        super(Callback, self).__init__()\n","        self.validation_data = val_data\n","        self.X = validation_data[0]\n","        self.Y = validation_data[1]\n","        self.history = []\n","    def on_epoch_end(self, epoch, logs={}):\n","        pred = self.model.predict(self.X)\n","        score = cohen_kappa_score(np.argmax(self.Y,axis=1),np.argmax(pred,axis=1),labels=[0,1,2,3,4],weights='quadratic')\n","        print(\"Epoch {} : QWK: {}\".format(epoch,score))\n","        self.history.append(score)\n","        if score >= max(self.history):\n","            print('saving checkpoint: ', score)\n","            self.model.save('/content/drive/MyDrive/CS331/Project/ResNet50_3_bestqwk.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gM5m-VyRj7z"},"source":["# borrowed from https://github.com/yu4u/mixup-generator\n","class MixupGenerator():\n","    def __init__(self, X_train, y_train, batch_size=32, alpha=0.2, shuffle=True, datagen=None):\n","        self.X_train = X_train\n","        self.y_train = y_train\n","        self.batch_size = batch_size\n","        self.alpha = alpha\n","        self.shuffle = shuffle\n","        self.sample_num = len(X_train)\n","        self.datagen = datagen\n","\n","    def __call__(self):\n","        while True:\n","            indexes = self.__get_exploration_order()\n","            itr_num = int(len(indexes) // (self.batch_size * 2))\n","\n","            for i in range(itr_num):\n","                batch_ids = indexes[i * self.batch_size * 2:(i + 1) * self.batch_size * 2]\n","                X, y = self.__data_generation(batch_ids)\n","\n","                yield X, y\n","\n","    def __get_exploration_order(self):\n","        indexes = np.arange(self.sample_num)\n","\n","        if self.shuffle:\n","            np.random.shuffle(indexes)\n","\n","        return indexes\n","\n","    def __data_generation(self, batch_ids):\n","        _, h, w, c = self.X_train.shape\n","        l = np.random.beta(self.alpha, self.alpha, self.batch_size)\n","        X_l = l.reshape(self.batch_size, 1, 1, 1)\n","        y_l = l.reshape(self.batch_size, 1)\n","\n","        X1 = self.X_train[batch_ids[:self.batch_size]]\n","        X2 = self.X_train[batch_ids[self.batch_size:]]\n","        X = X1 * X_l + X2 * (1 - X_l)\n","\n","        if self.datagen:\n","            for i in range(self.batch_size):\n","                X[i] = self.datagen.random_transform(X[i])\n","                X[i] = self.datagen.standardize(X[i])\n","\n","        if isinstance(self.y_train, list):\n","            y = []\n","\n","            for y_train_ in self.y_train:\n","                y1 = y_train_[batch_ids[:self.batch_size]]\n","                y2 = y_train_[batch_ids[self.batch_size:]]\n","                y.append(y1 * y_l + y2 * (1 - y_l))\n","        else:\n","            y1 = self.y_train[batch_ids[:self.batch_size]]\n","            y2 = self.y_train[batch_ids[self.batch_size:]]\n","            y = y1 * y_l + y2 * (1 - y_l)\n","\n","        return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-7wl2pkuRkZa"},"source":["batch_size = 32\n","img_size = 224"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8jFX5VTRmBL"},"source":["X_train=np.load('/content/drive/MyDrive/CS331/Project/Data_colored/X_train.npy')\n","Y_train=np.load('/content/drive/MyDrive/CS331/Project/Data_colored/Y_train.npy')\n","X_val=np.load('/content/drive/MyDrive/CS331/Project/Data_colored/X_val.npy')\n","Y_val=np.load('/content/drive/MyDrive/CS331/Project/Data_colored/Y_val.npy')\n","X_test = np.load('/content/drive/MyDrive/CS331/Project/Data_colored/X_test.npy')\n","Y_test = np.load('/content/drive/MyDrive/CS331/Project/Data_colored/Y_test.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Yp2cEqOf8Dx","executionInfo":{"elapsed":338,"status":"ok","timestamp":1624844917192,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"855decd1-c6b2-49cb-e812-301b4845a214"},"source":["Y_train_labels = np.argmax(Y_train,axis=1)\n","class_weights = class_weight.compute_class_weight('balanced',np.unique(Y_train_labels),Y_train_labels)\n","cls_wt_dict = dict(enumerate(class_weights))\n","print(cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{0: 0.40397022332506205, 1: 1.9304347826086956, 2: 0.7333333333333333, 3: 3.7282442748091604, 4: 2.6688524590163936}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sTdikyMgR2XS"},"source":["datagen = ImageDataGenerator(            \n","        zoom_range=0.15,  # set range for random zoom\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='constant',\n","        cval=0.,  # value used for fill_mode = \"constant\"\n","        horizontal_flip=True,  # randomly flip images\n","        vertical_flip=True,  # randomly flip images\n",")\n","training_generator = MixupGenerator(X_train, Y_train, batch_size=32, alpha=0.2, datagen=datagen)()\n","valid_generator = ImageDataGenerator(rescale=1./255)\n","validation = MixupGenerator(X_val, Y_val, batch_size=32, alpha=0.2, datagen=datagen)()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CA_OdIQDR5Lh"},"source":["from tensorflow import keras\n","class FocalLoss(keras.losses.Loss):\n","    def __init__(self, gamma=2., alpha=4.,\n","                 reduction=keras.losses.Reduction.AUTO, name='focal_loss'):\n","        \"\"\"Focal loss for multi-classification\n","        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n","        Notice: y_pred is probability after softmax\n","        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n","        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n","        Focal Loss for Dense Object Detection\n","        https://arxiv.org/abs/1708.02002\n","\n","        Keyword Arguments:\n","            gamma {float} -- (default: {2.0})\n","            alpha {float} -- (default: {4.0})\n","        \"\"\"\n","        super(FocalLoss, self).__init__(reduction=reduction,\n","                                        name=name)\n","        self.gamma = float(gamma)\n","        self.alpha = float(alpha)\n","\n","    def call(self, y_true, y_pred):\n","        \"\"\"\n","        Arguments:\n","            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n","            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n","\n","        Returns:\n","            [tensor] -- loss.\n","        \"\"\"\n","        print(y_true)\n","        print(y_pred)\n","        epsilon = 1.e-9\n","        y_true = tf.dtypes.cast(y_true, tf.float32)\n","        #y_true = tf.convert_to_tensor(y_true, tf.float32)\n","        print(\"y_true\", y_true)\n","        #y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n","\n","        model_out = tf.add(y_pred, epsilon)\n","        ce = tf.multiply(y_true, -tf.math.log(model_out))\n","        weight = tf.multiply(y_true, tf.pow(\n","            tf.subtract(1., model_out), self.gamma))\n","        fl = tf.multiply(self.alpha, tf.multiply(weight, ce))\n","        reduced_fl = tf.reduce_max(fl, axis=1)\n","        return tf.reduce_mean(reduced_fl)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Hnj7BwzUf7X"},"source":["#Categorical CrossEntropy Loss"]},{"cell_type":"code","metadata":{"id":"np7mkoUkgDvk"},"source":["def buildModel():\n","    ResNet50_model = ResNet50(include_top=False,weights=None,input_shape=(224,224,3))\n","    ResNet50_model.load_weights('/content/drive/MyDrive/CS331/Project/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n","#     model = keras.Sequential()\n","    \n","#     model.add(keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'same',activation ='relu', \n","#                       input_shape = (img_size,img_size,3)))\n","#     model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n","    \n","#     model.add(keras.layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","#     model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","    \n","#     model.add(keras.layers.Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","#     model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","\n","#     model.add(keras.layers.Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","#     model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","    \n","#     model.add(keras.layers.Flatten())\n","#     model.add(keras.layers.Dense(units = 512, activation = 'relu'))\n","#     model.add(keras.layers.Dense(units = 5, activation = 'softmax'))\n","    \n","    p  = tf.keras.layers.GlobalAveragePooling2D()(ResNet50_model.output)\n","#     fl = keras.layers.Flatten()(p)\n","#     d2 = keras.layers.Dense(units = 1024, activation = 'relu',kernel_regularizer= keras.regularizers.l2(0.001))(p)\n","#     d1 = keras.layers.Dense(units = 512, activation = 'relu',kernel_regularizer= keras.regularizers.l2(0.001))(d2)\n","    d = tf.keras.layers.Dropout(0.5)(p)\n","    d11 = tf.keras.layers.Dense(units = 2048, activation = 'relu',kernel_regularizer= keras.regularizers.l2(0.0001))(d)\n","    d12 = tf.keras.layers.Dropout(0.5)(d11)\n","    o1 = tf.keras.layers.Dense(units = 5, activation = 'softmax')(d12)\n","    model = tf.keras.models.Model(inputs = ResNet50_model.input,outputs = o1)\n","    sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(optimizer=sgd,loss='categorical_crossentropy', metrics = ['accuracy', 'AUC'])\n","    print(model.summary())\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sYal3hqGgI5z","executionInfo":{"elapsed":9374,"status":"ok","timestamp":1624782571791,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"da5f628c-dedf-4c64-ac03-bdd0e0d9e2e1"},"source":["my_model = buildModel()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n","                                                                 conv5_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2048)         4196352     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 2048)         0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 5)            10245       dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 27,794,309\n","Trainable params: 27,741,189\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"o9N50N06R5v7"},"source":["for layer in my_model.layers:\n","    layer.trainable = False\n","\n","for i in range(-5, 0):\n","    my_model.layers[i].trainable = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-Sstbw1gNb7","executionInfo":{"elapsed":41,"status":"ok","timestamp":1624781388268,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"391bba27-aeee-4088-f7ae-5fd2a5df6518"},"source":["my_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n","                                                                 conv5_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2048)         4196352     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 2048)         0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 5)            10245       dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 27,794,309\n","Trainable params: 4,206,597\n","Non-trainable params: 23,587,712\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OrlJT5tL22QN","executionInfo":{"elapsed":131991,"status":"ok","timestamp":1624585975355,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"cc66d682-81f1-4b42-8ef0-fde5fb65eee8"},"source":["new_model.fit(training_generator, epochs=2,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Epoch 1/2\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","76/76 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.8532 - auc: 0.8142Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","76/76 [==============================] - 74s 479ms/step - loss: 0.2226 - accuracy: 0.8532 - auc: 0.8142 - val_loss: 0.2583 - val_accuracy: 0.7861 - val_auc: 0.9630\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss improved from inf to 0.25832, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.25.h5\n","Epoch 0 : QWK: 0.8653537286005493\n","saving checkpoint:  0.8653537286005493\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/2\n","76/76 [==============================] - 34s 446ms/step - loss: 0.2251 - accuracy: 0.8388 - auc: 0.8031 - val_loss: 0.2437 - val_accuracy: 0.8148 - val_auc: 0.9708\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss improved from 0.25832 to 0.24367, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.25.h5\n","Epoch 1 : QWK: 0.8953963510482486\n","saving checkpoint:  0.8953963510482486\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fcb40065e90>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYiUmuyR3tXc","executionInfo":{"elapsed":131007,"status":"ok","timestamp":1624586118597,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"92186adc-7d28-47e2-d449-405240b687b4"},"source":["new_model.fit(training_generator, epochs=3,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","76/76 [==============================] - 36s 472ms/step - loss: 0.2202 - accuracy: 0.8606 - auc: 0.8116 - val_loss: 0.2430 - val_accuracy: 0.8221 - val_auc: 0.9701\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss improved from 0.24367 to 0.24305, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.25.h5\n","Epoch 0 : QWK: 0.8995853564760136\n","saving checkpoint:  0.8995853564760136\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/3\n","76/76 [==============================] - 35s 456ms/step - loss: 0.2188 - accuracy: 0.8623 - auc: 0.8151 - val_loss: 0.2521 - val_accuracy: 0.8107 - val_auc: 0.9661\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss did not improve from 0.24305\n","Epoch 1 : QWK: 0.879806797529054\n","Epoch 3/3\n","76/76 [==============================] - 34s 451ms/step - loss: 0.2175 - accuracy: 0.8586 - auc: 0.8104 - val_loss: 0.2445 - val_accuracy: 0.8115 - val_auc: 0.9692\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00003: val_loss did not improve from 0.24305\n","Epoch 2 : QWK: 0.8914941485956326\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fcade3d73d0>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"GF-HxHgzU9xA"},"source":["y_pre = new_model.predict(X_test)\n","y_true = [np.argmax(element) for element in Y_test]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":753},"id":"hCP544sA4Qik","executionInfo":{"elapsed":826,"status":"ok","timestamp":1624586147166,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"f56d4d69-175b-4b05-a870-6aed0932fb5d"},"source":["import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, plot_confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt     \n","\n","y_pred_classes = [np.argmax(element) for element in y_pre]\n"," \n","print(\"Classification Report: \\n\", classification_report(y_true, y_pred_classes))\n","\n","cnf_matrix = confusion_matrix(y_true, y_pred_classes)\n","\n","labels = [\"No DR\",\"Mild\",\"Moderate\",\"Severe\",\"Proliferative DR\"]\n","plt.figure(figsize=(10,8))\n","ax= plt.subplot()\n","sns.heatmap(cnf_matrix, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n","\n","# labels, title and ticks\n","label_font = {'size':'16'}\n","ax.set_xlabel('Predicted labels', fontdict=label_font);ax.set_ylabel('True labels',fontdict=label_font); \n","title_font = {'size':'18'}\n","ax.set_title('Confusion Matrix',fontdict=title_font);\n","\n","ax.xaxis.set_ticklabels(labels); \n","ax.yaxis.set_ticklabels(labels);\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Classification Report: \n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00       186\n","           1       0.76      0.74      0.75        35\n","           2       0.88      0.88      0.88       102\n","           3       0.91      0.59      0.71        17\n","           4       0.79      0.96      0.87        27\n","\n","    accuracy                           0.92       367\n","   macro avg       0.87      0.84      0.84       367\n","weighted avg       0.92      0.92      0.92       367\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x576 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"JosNOrdnUKlC"},"source":["#Focal Loss"]},{"cell_type":"code","metadata":{"id":"35YVobgCVYnc"},"source":["def buildModel():\n","    ResNet50_model = ResNet50(include_top=False,weights=None,input_shape=(224,224,3))\n","    ResNet50_model.load_weights('/content/drive/MyDrive/CS331/Project/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n","#     model = keras.Sequential()\n","    \n","#     model.add(keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'same',activation ='relu', \n","#                       input_shape = (img_size,img_size,3)))\n","#     model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n","    \n","#     model.add(keras.layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","#     model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","    \n","#     model.add(keras.layers.Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","#     model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","\n","#     model.add(keras.layers.Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","#     model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","    \n","#     model.add(keras.layers.Flatten())\n","#     model.add(keras.layers.Dense(units = 512, activation = 'relu'))\n","#     model.add(keras.layers.Dense(units = 5, activation = 'softmax'))\n","    \n","    p  = tf.keras.layers.GlobalAveragePooling2D()(ResNet50_model.output)\n","#     fl = keras.layers.Flatten()(p)\n","#     d2 = keras.layers.Dense(units = 1024, activation = 'relu',kernel_regularizer= keras.regularizers.l2(0.001))(p)\n","#     d1 = keras.layers.Dense(units = 512, activation = 'relu',kernel_regularizer= keras.regularizers.l2(0.001))(d2)\n","    d = tf.keras.layers.Dropout(0.5)(p)\n","    d11 = tf.keras.layers.Dense(units = 2048, activation = 'relu',kernel_regularizer= keras.regularizers.l2(0.0001))(d)\n","    d12 = tf.keras.layers.Dropout(0.5)(d11)\n","    o1 = tf.keras.layers.Dense(units = 5, activation = 'softmax')(d12)\n","    model = tf.keras.models.Model(inputs = ResNet50_model.input,outputs = o1)\n","    sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(optimizer=sgd,loss=FocalLoss(alpha=0.5), metrics = ['accuracy', 'AUC'])\n","    print(model.summary())\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UcThcmTXSZC4"},"source":["class QWKCallback(Callback):\n","    def __init__(self,val_data):\n","        super(Callback, self).__init__()\n","        self.validation_data = val_data\n","        self.X = validation_data[0]\n","        self.Y = validation_data[1]\n","        self.history = []\n","    def on_epoch_end(self, epoch, logs={}):\n","        pred = self.model.predict(self.X)\n","        score = cohen_kappa_score(np.argmax(self.Y,axis=1),np.argmax(pred,axis=1),labels=[0,1,2,3,4],weights='quadratic')\n","        print(\"Epoch {} : QWK: {}\".format(epoch,score))\n","        self.history.append(score)\n","        if score >= max(self.history):\n","            print('saving checkpoint: ', score)\n","            self.model.save('/content/drive/MyDrive/CS331/Project/FocalLoss_0.5.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8NhYqG8kVivO","executionInfo":{"elapsed":9374,"status":"ok","timestamp":1624782571791,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"da5f628c-dedf-4c64-ac03-bdd0e0d9e2e1"},"source":["my_model = buildModel()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n","                                                                 conv5_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2048)         4196352     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 2048)         0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 5)            10245       dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 27,794,309\n","Trainable params: 27,741,189\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ImBRUigESO5J"},"source":["EPOCHS = 50\n","validation_data=(X_val, Y_val)\n","earlystop = keras.callbacks.EarlyStopping(patience=10)\n","learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n","                                            patience=2, \n","                                            verbose=1, \n","                                            factor=0.5, \n","                                            min_lr=0.00001)\n","checkpoint = keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/data_AdvancedCV/Project/FocalLoss_0.5.h5', monitor='val_loss', verbose=1, \n","                             save_best_only=True, mode='min', save_weights_only = True)\n","qwk = QWKCallback((X_val,Y_val))\n","mycallbacks = [earlystop, learning_rate_reduction,checkpoint,qwk]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYLxoaNmgToc","executionInfo":{"elapsed":147199,"status":"ok","timestamp":1624781535442,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"3a75af65-de18-47ee-fdd0-8386f44faf33"},"source":["my_model.fit(training_generator, epochs=2,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Epoch 1/2\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","76/76 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.6081 - auc: 0.7669Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","76/76 [==============================] - 74s 482ms/step - loss: 0.3603 - accuracy: 0.6081 - auc: 0.7669 - val_loss: 0.4087 - val_accuracy: 0.2730 - val_auc: 0.7177\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss improved from inf to 0.40871, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 0 : QWK: 0.0\n","saving checkpoint:  0.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/2\n","76/76 [==============================] - 35s 457ms/step - loss: 0.3051 - accuracy: 0.7027 - auc: 0.7888 - val_loss: 0.4024 - val_accuracy: 0.4885 - val_auc: 0.7740\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss improved from 0.40871 to 0.40240, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 1 : QWK: 0.0\n","saving checkpoint:  0.0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f721eb30a50>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"jzG_JaKfSTyX"},"source":["for layer in my_model.layers:\n","    layer.trainable = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pNWkid_Vhze5","executionInfo":{"elapsed":142573,"status":"ok","timestamp":1624781714392,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"beb36d3b-1a55-4393-8116-470d23cecdac"},"source":["my_model.fit(training_generator, epochs=2,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","76/76 [==============================] - 36s 469ms/step - loss: 0.2883 - accuracy: 0.7282 - auc: 0.7925 - val_loss: 0.4053 - val_accuracy: 0.4885 - val_auc: 0.8009\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss did not improve from 0.40240\n","Epoch 0 : QWK: 0.0\n","saving checkpoint:  0.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/2\n","76/76 [==============================] - 35s 455ms/step - loss: 0.2780 - accuracy: 0.7463 - auc: 0.7920 - val_loss: 0.4367 - val_accuracy: 0.4885 - val_auc: 0.7896\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss did not improve from 0.40240\n","Epoch 1 : QWK: 0.0\n","saving checkpoint:  0.0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f71ae5dbbd0>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9UzHAcX-inzr","executionInfo":{"elapsed":99387,"status":"ok","timestamp":1624781900177,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"950a6a23-e4e2-4d04-b597-adf7e03e4153"},"source":["my_model.fit(training_generator, epochs=2,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","76/76 [==============================] - 36s 476ms/step - loss: 0.2743 - accuracy: 0.7504 - auc: 0.7928 - val_loss: 0.4797 - val_accuracy: 0.4885 - val_auc: 0.7732\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss did not improve from 0.40240\n","Epoch 0 : QWK: 0.0\n","saving checkpoint:  0.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/2\n","76/76 [==============================] - 35s 459ms/step - loss: 0.2626 - accuracy: 0.7829 - auc: 0.8034 - val_loss: 0.4884 - val_accuracy: 0.4943 - val_auc: 0.7686\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss did not improve from 0.40240\n","Epoch 1 : QWK: 0.028218240843361886\n","saving checkpoint:  0.028218240843361886\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f71ae3e1090>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWgnDCCmjqq_","executionInfo":{"elapsed":142745,"status":"ok","timestamp":1624782200086,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"2d9cfb28-c964-4f20-c9f0-8f5fb8f06338"},"source":["my_model.fit(training_generator, epochs=2,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","76/76 [==============================] - 36s 473ms/step - loss: 0.2611 - accuracy: 0.7833 - auc: 0.8007 - val_loss: 0.5153 - val_accuracy: 0.4984 - val_auc: 0.8025\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss did not improve from 0.40240\n","Epoch 0 : QWK: 0.030065118277557867\n","saving checkpoint:  0.030065118277557867\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/2\n","76/76 [==============================] - 35s 458ms/step - loss: 0.2622 - accuracy: 0.7874 - auc: 0.7952 - val_loss: 0.5028 - val_accuracy: 0.5246 - val_auc: 0.8146\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss did not improve from 0.40240\n","Epoch 1 : QWK: 0.07841638549254992\n","saving checkpoint:  0.07841638549254992\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f71ae347190>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvLtIHDilJRL","executionInfo":{"elapsed":8811,"status":"ok","timestamp":1624806542940,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"6885f884-11be-493b-a0bc-5adc4bf20690"},"source":["new_model = buildModel()\n","new_model.load_weights('/content/drive/MyDrive/CS331/Project/FocalLoss_0.5.h5')\n","for layer in new_model.layers:\n","    layer.trainable = True"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n","__________________________________________________________________________________________________\n","conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n","__________________________________________________________________________________________________\n","pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n","__________________________________________________________________________________________________\n","pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n","__________________________________________________________________________________________________\n","conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n","__________________________________________________________________________________________________\n","conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n","                                                                 conv2_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n","                                                                 conv2_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n","                                                                 conv2_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n","                                                                 conv3_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n","                                                                 conv3_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n","                                                                 conv3_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n","                                                                 conv3_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n","                                                                 conv4_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n","                                                                 conv4_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n","                                                                 conv4_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n","                                                                 conv4_block4_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n","                                                                 conv4_block5_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n","__________________________________________________________________________________________________\n","conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n","                                                                 conv4_block6_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n","                                                                 conv5_block1_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n","                                                                 conv5_block2_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n","__________________________________________________________________________________________________\n","conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n","__________________________________________________________________________________________________\n","conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n","                                                                 conv5_block3_3_bn[0][0]          \n","__________________________________________________________________________________________________\n","conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2048)         4196352     dropout[0][0]                    \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 2048)         0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 5)            10245       dropout_1[0][0]                  \n","==================================================================================================\n","Total params: 27,794,309\n","Trainable params: 27,741,189\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ro2tuExGlPGy","executionInfo":{"elapsed":251207,"status":"ok","timestamp":1624782932501,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"a3278cda-fc65-476d-dca9-4c680f767fd9"},"source":["new_model.fit(training_generator, epochs=5,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Epoch 1/5\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model_2/dense_5/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model_2/dense_5/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","76/76 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.7368 - auc: 0.7920Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","Tensor(\"model_2/dense_5/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","76/76 [==============================] - 74s 487ms/step - loss: 0.2882 - accuracy: 0.7368 - auc: 0.7920 - val_loss: 0.3989 - val_accuracy: 0.4902 - val_auc: 0.7936\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss improved from inf to 0.39890, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 0 : QWK: 0.010741031864629269\n","saving checkpoint:  0.010741031864629269\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/5\n","76/76 [==============================] - 34s 453ms/step - loss: 0.2787 - accuracy: 0.7525 - auc: 0.8023 - val_loss: 0.4923 - val_accuracy: 0.4885 - val_auc: 0.7880\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss did not improve from 0.39890\n","Epoch 1 : QWK: 0.0\n","Epoch 3/5\n","76/76 [==============================] - 34s 454ms/step - loss: 0.2722 - accuracy: 0.7632 - auc: 0.7968 - val_loss: 0.4679 - val_accuracy: 0.4885 - val_auc: 0.8035\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00003: val_loss did not improve from 0.39890\n","Epoch 2 : QWK: 0.0019361276411352657\n","Epoch 4/5\n","76/76 [==============================] - 34s 454ms/step - loss: 0.2626 - accuracy: 0.7903 - auc: 0.8023 - val_loss: 0.5723 - val_accuracy: 0.4885 - val_auc: 0.7896\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00004: val_loss did not improve from 0.39890\n","Epoch 3 : QWK: 0.0\n","Epoch 5/5\n","76/76 [==============================] - 34s 452ms/step - loss: 0.2674 - accuracy: 0.7747 - auc: 0.8026 - val_loss: 0.4903 - val_accuracy: 0.4861 - val_auc: 0.7862\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00005: val_loss did not improve from 0.39890\n","Epoch 4 : QWK: 0.049224595905196344\n","saving checkpoint:  0.049224595905196344\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f29859dff10>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"euFk7CJSonuo","executionInfo":{"elapsed":507047,"status":"ok","timestamp":1624783986784,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"ca46070e-8976-4286-e63e-553cdf8e8d8e"},"source":["new_model.fit(training_generator, epochs=10,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Epoch 1/10\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","76/76 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.7422 - auc: 0.7985Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","76/76 [==============================] - 74s 490ms/step - loss: 0.2794 - accuracy: 0.7422 - auc: 0.7985 - val_loss: 0.4489 - val_accuracy: 0.4885 - val_auc: 0.7590\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss improved from inf to 0.44891, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 0 : QWK: 0.0\n","saving checkpoint:  0.0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/10\n","76/76 [==============================] - 34s 454ms/step - loss: 0.2726 - accuracy: 0.7582 - auc: 0.7942 - val_loss: 0.4627 - val_accuracy: 0.4885 - val_auc: 0.7690\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss did not improve from 0.44891\n","Epoch 1 : QWK: 0.0\n","saving checkpoint:  0.0\n","Epoch 3/10\n","76/76 [==============================] - 35s 461ms/step - loss: 0.2641 - accuracy: 0.7882 - auc: 0.7999 - val_loss: 0.4606 - val_accuracy: 0.4934 - val_auc: 0.7810\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00003: val_loss did not improve from 0.44891\n","Epoch 2 : QWK: 0.11505903219449276\n","saving checkpoint:  0.11505903219449276\n","Epoch 4/10\n","76/76 [==============================] - 35s 456ms/step - loss: 0.2667 - accuracy: 0.7780 - auc: 0.8033 - val_loss: 0.4623 - val_accuracy: 0.4910 - val_auc: 0.7705\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00004: val_loss did not improve from 0.44891\n","Epoch 3 : QWK: 0.011166006195164946\n","Epoch 5/10\n","76/76 [==============================] - 34s 454ms/step - loss: 0.2620 - accuracy: 0.7961 - auc: 0.7996 - val_loss: 0.4328 - val_accuracy: 0.5262 - val_auc: 0.7989\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00005: val_loss improved from 0.44891 to 0.43276, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 4 : QWK: 0.09542433528899952\n","Epoch 6/10\n","76/76 [==============================] - 34s 451ms/step - loss: 0.2560 - accuracy: 0.8084 - auc: 0.8085 - val_loss: 0.3990 - val_accuracy: 0.6402 - val_auc: 0.8468\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00006: val_loss improved from 0.43276 to 0.39905, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 5 : QWK: 0.4360416386750865\n","saving checkpoint:  0.4360416386750865\n","Epoch 7/10\n","76/76 [==============================] - 35s 468ms/step - loss: 0.2503 - accuracy: 0.8129 - auc: 0.8053 - val_loss: 0.4076 - val_accuracy: 0.6623 - val_auc: 0.8520\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00007: val_loss did not improve from 0.39905\n","Epoch 6 : QWK: 0.5108678069814626\n","saving checkpoint:  0.5108678069814626\n","Epoch 8/10\n","76/76 [==============================] - 35s 458ms/step - loss: 0.2474 - accuracy: 0.8248 - auc: 0.8065 - val_loss: 0.3685 - val_accuracy: 0.7049 - val_auc: 0.8720\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00008: val_loss improved from 0.39905 to 0.36846, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 7 : QWK: 0.6521976180073223\n","saving checkpoint:  0.6521976180073223\n","Epoch 9/10\n","76/76 [==============================] - 35s 468ms/step - loss: 0.2482 - accuracy: 0.8137 - auc: 0.8098 - val_loss: 0.3483 - val_accuracy: 0.7262 - val_auc: 0.8886\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00009: val_loss improved from 0.36846 to 0.34827, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 8 : QWK: 0.6867720181746662\n","saving checkpoint:  0.6867720181746662\n","Epoch 10/10\n","76/76 [==============================] - 35s 468ms/step - loss: 0.2459 - accuracy: 0.8228 - auc: 0.8109 - val_loss: 0.3108 - val_accuracy: 0.7418 - val_auc: 0.9264\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00010: val_loss improved from 0.34827 to 0.31078, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 9 : QWK: 0.7394521783741084\n","saving checkpoint:  0.7394521783741084\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7dcf376050>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIey0muhtdls","outputId":"47afa523-906e-41d6-c354-c86dac3a7054"},"source":["new_model.fit(training_generator, epochs=10,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Epoch 1/10\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","76/76 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.8203 - auc: 0.8049Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","76/76 [==============================] - 74s 487ms/step - loss: 0.2423 - accuracy: 0.8203 - auc: 0.8049 - val_loss: 0.2994 - val_accuracy: 0.7623 - val_auc: 0.9362\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss improved from inf to 0.29943, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 0 : QWK: 0.7972237089696561\n","saving checkpoint:  0.7972237089696561\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/10\n","76/76 [==============================] - 35s 455ms/step - loss: 0.2406 - accuracy: 0.8355 - auc: 0.8073 - val_loss: 0.2764 - val_accuracy: 0.7877 - val_auc: 0.9571\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss improved from 0.29943 to 0.27643, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 1 : QWK: 0.8457378212498251\n","saving checkpoint:  0.8457378212498251\n","Epoch 3/10\n","76/76 [==============================] - 35s 459ms/step - loss: 0.2368 - accuracy: 0.8421 - auc: 0.8121 - val_loss: 0.2847 - val_accuracy: 0.7926 - val_auc: 0.9557\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00003: val_loss did not improve from 0.27643\n","Epoch 2 : QWK: 0.8368739331248221\n","Epoch 4/10\n","76/76 [==============================] - 35s 460ms/step - loss: 0.2387 - accuracy: 0.8372 - auc: 0.8197 - val_loss: 0.2762 - val_accuracy: 0.8098 - val_auc: 0.9611\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00004: val_loss improved from 0.27643 to 0.27619, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 3 : QWK: 0.8705420033491043\n","saving checkpoint:  0.8705420033491043\n","Epoch 5/10\n","76/76 [==============================] - 35s 462ms/step - loss: 0.2378 - accuracy: 0.8425 - auc: 0.8157 - val_loss: 0.2748 - val_accuracy: 0.8049 - val_auc: 0.9635\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00005: val_loss improved from 0.27619 to 0.27477, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 4 : QWK: 0.8603647925577764\n","Epoch 6/10\n","76/76 [==============================] - 35s 462ms/step - loss: 0.2330 - accuracy: 0.8651 - auc: 0.8144 - val_loss: 0.2716 - val_accuracy: 0.7943 - val_auc: 0.9609\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00006: val_loss improved from 0.27477 to 0.27160, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 5 : QWK: 0.875082362828082\n","saving checkpoint:  0.875082362828082\n","Epoch 7/10\n","76/76 [==============================] - 35s 459ms/step - loss: 0.2292 - accuracy: 0.8524 - auc: 0.8145 - val_loss: 0.2799 - val_accuracy: 0.7975 - val_auc: 0.9592\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00007: val_loss did not improve from 0.27160\n","Epoch 6 : QWK: 0.8553203777731821\n","Epoch 8/10\n","76/76 [==============================] - 35s 462ms/step - loss: 0.2296 - accuracy: 0.8598 - auc: 0.8191 - val_loss: 0.2726 - val_accuracy: 0.7762 - val_auc: 0.9585\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00008: val_loss did not improve from 0.27160\n","Epoch 7 : QWK: 0.8741167816457583\n","Epoch 9/10\n","76/76 [==============================] - 35s 457ms/step - loss: 0.2278 - accuracy: 0.8631 - auc: 0.8153 - val_loss: 0.2671 - val_accuracy: 0.7934 - val_auc: 0.9613\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00009: val_loss improved from 0.27160 to 0.26711, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9DgTbxGv7RW","outputId":"a0f69ed7-71fb-4c48-b5e2-d4cbecc0b1f7"},"source":["new_model.fit(training_generator, epochs=10,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Epoch 1/10\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","76/76 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.8787 - auc: 0.8051Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","76/76 [==============================] - 74s 485ms/step - loss: 0.2227 - accuracy: 0.8787 - auc: 0.8051 - val_loss: 0.2830 - val_accuracy: 0.7828 - val_auc: 0.9567\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss improved from inf to 0.28300, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 0 : QWK: 0.8655183563580781\n","saving checkpoint:  0.8655183563580781\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/10\n","76/76 [==============================] - 36s 471ms/step - loss: 0.2282 - accuracy: 0.8590 - auc: 0.8134 - val_loss: 0.2725 - val_accuracy: 0.7770 - val_auc: 0.9582\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss improved from 0.28300 to 0.27250, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 1 : QWK: 0.879764830610573\n","saving checkpoint:  0.879764830610573\n","Epoch 3/10\n","76/76 [==============================] - 35s 465ms/step - loss: 0.2221 - accuracy: 0.8853 - auc: 0.8234 - val_loss: 0.2958 - val_accuracy: 0.7262 - val_auc: 0.9462\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00003: val_loss did not improve from 0.27250\n","Epoch 2 : QWK: 0.8220108724071359\n","Epoch 4/10\n","76/76 [==============================] - 34s 452ms/step - loss: 0.2225 - accuracy: 0.8729 - auc: 0.8209 - val_loss: 0.2749 - val_accuracy: 0.7861 - val_auc: 0.9568\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00004: val_loss did not improve from 0.27250\n","Epoch 3 : QWK: 0.8576638097395504\n","Epoch 5/10\n","76/76 [==============================] - 34s 449ms/step - loss: 0.2195 - accuracy: 0.8771 - auc: 0.8234 - val_loss: 0.2782 - val_accuracy: 0.8098 - val_auc: 0.9606\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00005: val_loss did not improve from 0.27250\n","Epoch 4 : QWK: 0.8740328984328901\n","Epoch 6/10\n","76/76 [==============================] - 35s 459ms/step - loss: 0.2162 - accuracy: 0.8976 - auc: 0.8241 - val_loss: 0.2886 - val_accuracy: 0.7762 - val_auc: 0.9537\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00006: val_loss did not improve from 0.27250\n","Epoch 5 : QWK: 0.8462816332576466\n","Epoch 7/10\n","76/76 [==============================] - 35s 456ms/step - loss: 0.2194 - accuracy: 0.8840 - auc: 0.8232 - val_loss: 0.2979 - val_accuracy: 0.7574 - val_auc: 0.9521\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00007: val_loss did not improve from 0.27250\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IVlxDaFIyN1d","executionInfo":{"elapsed":267508,"status":"ok","timestamp":1624786230395,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"491cc114-bfe4-4169-832c-2898e20abdd7"},"source":["new_model.fit(training_generator, epochs=5,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Epoch 1/5\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","76/76 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.8705 - auc: 0.8174Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","76/76 [==============================] - 75s 492ms/step - loss: 0.2246 - accuracy: 0.8705 - auc: 0.8174 - val_loss: 0.2744 - val_accuracy: 0.7984 - val_auc: 0.9598\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss improved from inf to 0.27440, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 0 : QWK: 0.8807652328607442\n","saving checkpoint:  0.8807652328607442\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/5\n","76/76 [==============================] - 35s 456ms/step - loss: 0.2208 - accuracy: 0.8816 - auc: 0.8194 - val_loss: 0.2939 - val_accuracy: 0.7893 - val_auc: 0.9553\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss did not improve from 0.27440\n","Epoch 1 : QWK: 0.8428365536777842\n","Epoch 3/5\n","76/76 [==============================] - 34s 449ms/step - loss: 0.2212 - accuracy: 0.8775 - auc: 0.8188 - val_loss: 0.2998 - val_accuracy: 0.7320 - val_auc: 0.9433\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00003: val_loss did not improve from 0.27440\n","Epoch 2 : QWK: 0.8438314143975498\n","Epoch 4/5\n","76/76 [==============================] - 34s 453ms/step - loss: 0.2171 - accuracy: 0.8828 - auc: 0.8115 - val_loss: 0.2742 - val_accuracy: 0.8098 - val_auc: 0.9609\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00004: val_loss improved from 0.27440 to 0.27420, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 3 : QWK: 0.8818289389212566\n","saving checkpoint:  0.8818289389212566\n","Epoch 5/5\n","76/76 [==============================] - 36s 478ms/step - loss: 0.2138 - accuracy: 0.8951 - auc: 0.8174 - val_loss: 0.2925 - val_accuracy: 0.7918 - val_auc: 0.9536\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00005: val_loss did not improve from 0.27420\n","Epoch 4 : QWK: 0.8422824192790611\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f176039e950>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ha32k6bQ0ydS","executionInfo":{"elapsed":263899,"status":"ok","timestamp":1624786944396,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"7b6e9b02-9a04-485c-fc06-e28aea18d700"},"source":["new_model.fit(training_generator, epochs=5,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Epoch 1/5\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","76/76 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.8931 - auc: 0.8181Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","76/76 [==============================] - 74s 492ms/step - loss: 0.2157 - accuracy: 0.8931 - auc: 0.8181 - val_loss: 0.2828 - val_accuracy: 0.7910 - val_auc: 0.9604\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss improved from inf to 0.28278, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 0 : QWK: 0.8590619291421505\n","saving checkpoint:  0.8590619291421505\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/5\n","76/76 [==============================] - 36s 474ms/step - loss: 0.2148 - accuracy: 0.9001 - auc: 0.8225 - val_loss: 0.2759 - val_accuracy: 0.8090 - val_auc: 0.9610\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss improved from 0.28278 to 0.27588, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 1 : QWK: 0.8824284471813738\n","saving checkpoint:  0.8824284471813738\n","Epoch 3/5\n","76/76 [==============================] - 36s 470ms/step - loss: 0.2133 - accuracy: 0.8993 - auc: 0.8178 - val_loss: 0.2786 - val_accuracy: 0.8090 - val_auc: 0.9611\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00003: val_loss did not improve from 0.27588\n","Epoch 2 : QWK: 0.8746277348211843\n","Epoch 4/5\n","76/76 [==============================] - 35s 457ms/step - loss: 0.2149 - accuracy: 0.8919 - auc: 0.8233 - val_loss: 0.2774 - val_accuracy: 0.7885 - val_auc: 0.9578\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00004: val_loss did not improve from 0.27588\n","Epoch 3 : QWK: 0.8625629799319228\n","Epoch 5/5\n","76/76 [==============================] - 35s 459ms/step - loss: 0.2103 - accuracy: 0.9079 - auc: 0.8232 - val_loss: 0.2810 - val_accuracy: 0.7943 - val_auc: 0.9532\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00005: val_loss did not improve from 0.27588\n","Epoch 4 : QWK: 0.8847247776755597\n","saving checkpoint:  0.8847247776755597\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f76a004b710>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DGtUeGwb2oTM","outputId":"47d6acc7-33d4-4e69-954b-976121ac24e9"},"source":["new_model.fit(training_generator, epochs=10,\n","             steps_per_epoch=X_train.shape[0] // batch_size,\n","             validation_data=(X_val, Y_val), verbose=1, \n","             callbacks = [mycallbacks],\n","             class_weight = cls_wt_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","Epoch 1/10\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, None), dtype=float32)\n","76/76 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.8877 - auc: 0.8200Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","Tensor(\"model/dense_1/Softmax:0\", shape=(None, 5), dtype=float32)\n","y_true Tensor(\"IteratorGetNext:1\", shape=(None, 5), dtype=float32)\n","76/76 [==============================] - 75s 494ms/step - loss: 0.2145 - accuracy: 0.8877 - auc: 0.8200 - val_loss: 0.2817 - val_accuracy: 0.7934 - val_auc: 0.9584\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00001: val_loss improved from inf to 0.28166, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 0 : QWK: 0.8864597537756966\n","saving checkpoint:  0.8864597537756966\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/10\n","76/76 [==============================] - 35s 460ms/step - loss: 0.2134 - accuracy: 0.8902 - auc: 0.8197 - val_loss: 0.2862 - val_accuracy: 0.7516 - val_auc: 0.9481\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00002: val_loss did not improve from 0.28166\n","Epoch 1 : QWK: 0.8634589135554502\n","Epoch 3/10\n","76/76 [==============================] - 35s 456ms/step - loss: 0.2139 - accuracy: 0.8923 - auc: 0.8277 - val_loss: 0.2859 - val_accuracy: 0.7869 - val_auc: 0.9517\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00003: val_loss did not improve from 0.28166\n","Epoch 2 : QWK: 0.8557526100715283\n","Epoch 4/10\n","76/76 [==============================] - 35s 456ms/step - loss: 0.2080 - accuracy: 0.9030 - auc: 0.8187 - val_loss: 0.2822 - val_accuracy: 0.8090 - val_auc: 0.9605\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00004: val_loss did not improve from 0.28166\n","Epoch 3 : QWK: 0.8636293740758995\n","Epoch 5/10\n","76/76 [==============================] - 35s 457ms/step - loss: 0.2085 - accuracy: 0.9079 - auc: 0.8307 - val_loss: 0.2913 - val_accuracy: 0.7918 - val_auc: 0.9567\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00005: val_loss did not improve from 0.28166\n","Epoch 4 : QWK: 0.8673569842029052\n","Epoch 6/10\n","76/76 [==============================] - 36s 477ms/step - loss: 0.2101 - accuracy: 0.8956 - auc: 0.8259 - val_loss: 0.2824 - val_accuracy: 0.7992 - val_auc: 0.9557\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00006: val_loss did not improve from 0.28166\n","Epoch 5 : QWK: 0.8748779607415179\n","Epoch 7/10\n","76/76 [==============================] - 36s 476ms/step - loss: 0.2096 - accuracy: 0.8943 - auc: 0.8299 - val_loss: 0.2839 - val_accuracy: 0.8139 - val_auc: 0.9589\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00007: val_loss did not improve from 0.28166\n","Epoch 6 : QWK: 0.8774371936618659\n","Epoch 8/10\n","76/76 [==============================] - 34s 455ms/step - loss: 0.2073 - accuracy: 0.9021 - auc: 0.8263 - val_loss: 0.2776 - val_accuracy: 0.7779 - val_auc: 0.9550\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00008: val_loss improved from 0.28166 to 0.27758, saving model to /content/drive/MyDrive/NhanDang/Data/3k6/FocalLoss_0.5.h5\n","Epoch 7 : QWK: 0.865015991317627\n","Epoch 9/10\n","76/76 [==============================] - 35s 466ms/step - loss: 0.2063 - accuracy: 0.9095 - auc: 0.8239 - val_loss: 0.2843 - val_accuracy: 0.7951 - val_auc: 0.9589\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,auc,val_loss,val_accuracy,val_auc,lr\n","\n","Epoch 00009: val_loss did not improve from 0.27758\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DAwDSG3uS-FS"},"source":["y_pre = new_model.predict(X_test)\n","y_true = [np.argmax(element) for element in Y_test]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":753},"id":"OBDIiM282W2P","executionInfo":{"elapsed":997,"status":"ok","timestamp":1624786958325,"user":{"displayName":"Phuong Le Thi Ngoc","photoUrl":"","userId":"14072577034064178294"},"user_tz":-420},"outputId":"a6458003-d361-4936-dcb1-4e28845c57d5"},"source":["import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, plot_confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt     \n","\n","y_pred_classes = [np.argmax(element) for element in y_pre]\n"," \n","print(\"Classification Report: \\n\", classification_report(y_true, y_pred_classes))\n","\n","cnf_matrix = confusion_matrix(y_true, y_pred_classes)\n","\n","labels = [\"No DR\",\"Mild\",\"Moderate\",\"Severe\",\"Proliferative DR\"]\n","plt.figure(figsize=(10,8))\n","ax= plt.subplot()\n","sns.heatmap(cnf_matrix, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n","\n","# labels, title and ticks\n","label_font = {'size':'16'}\n","ax.set_xlabel('Predicted labels', fontdict=label_font);ax.set_ylabel('True labels',fontdict=label_font); \n","title_font = {'size':'18'}\n","ax.set_title('Confusion Matrix',fontdict=title_font);\n","\n","ax.xaxis.set_ticklabels(labels); \n","ax.yaxis.set_ticklabels(labels);\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Classification Report: \n","               precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99       186\n","           1       0.93      0.71      0.81        35\n","           2       0.89      0.92      0.90       102\n","           3       0.76      0.94      0.84        17\n","           4       0.93      1.00      0.96        27\n","\n","    accuracy                           0.94       367\n","   macro avg       0.90      0.91      0.90       367\n","weighted avg       0.95      0.94      0.94       367\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x576 with 2 Axes>"]},"metadata":{"tags":[]}}]}]}